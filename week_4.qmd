---
title: "week_4"
format: 
  html:
    code-fold: true
    code-tools: true
    embed-resources: true
editor: visual
---

Note: Closely follows the algorithm set in Ben-Hur and Elisseeff paper: A stability based method for discovering structure in clustered data (2002)

## Imports

```{r}
#| label: imports
#| message: false
library(tidyclust)
library(tidyverse)
library(tidymodels)
library(plotly)
library(foreach)
library(doParallel)
registerDoParallel(cores = detectCores() - 1)
set.seed(599)
```

## Resample Function

```{r}
#| label: resample-function
resample_function <- function(data = data,
                              k = 3,
                              number_of_resamples = 15,
                              proportion_resample = 0.9,
                              starting_seed = 599) {
  start <- Sys.time()
  data <- data |> 
    drop_na()
  # data <- data[sample(nrow(data)), ]
  data$index <- 1:nrow(data)
  results <- list()
  
  # For loop
  results <- foreach(i = 1:number_of_resamples,
                     .packages = c("tidyclust", "dplyr", "tidymodels")) %dopar% {
    # Reproducibility over parallel
    set.seed(starting_seed + i)
    result_matrix <- matrix(0, nrow = nrow(data), ncol = nrow(data))
    # 80% resample
    random_sample <- data |> 
      filter(index %in% sample(index, proportion_resample * nrow(data)))
    
    # Run k-means on resample
    # kmeans <- k_means(num_clusters = k) |>
    #   fit(~ bill_length_mm + flipper_length_mm,
    #       data = random_sample)

    kmeans <- k_means(num_clusters = k) |>
      fit(~ X1 + X2,
          data = random_sample)
    
    intermediate <- data.frame(random_sample$index,
                               extract_cluster_assignment(kmeans) |>
                                 mutate(.cluster = as.character(.cluster)),
                               stringsAsFactors = FALSE)
    colnames(intermediate) <- c("index", "cluster")
    
    # I don't know how to vectorize this :(
    for (n in 1:(nrow(intermediate) - 1)) {
      for (m in (n + 1):nrow(intermediate)) {
        # if the points are the same then set to NA
        if (intermediate[n, ]$index != intermediate[m, ]$index) {
          # get first pointer cluster
          first <- intermediate[n, ]$cluster
          # get second pointer cluster
          second <- intermediate[m, ]$cluster
  
          # if clusters are the same
          if (first == second) {
            result_matrix[intermediate[n, ]$index, intermediate[m, ]$index] <- 1
          } else {
            # if clusters are different
            result_matrix[intermediate[n, ]$index, intermediate[m, ]$index] <- -1
          }
        }
      }
    }
    result_matrix[lower.tri(result_matrix, diag = TRUE)] <- NA
    result_matrix
  }
  end = Sys.time()
  print(paste0("Number of seconds taken is: ", end - start))
  return(results)
}
```

## For one k, return the mean matrix

```{r}
one_k_mean_matrix <- function(data = data,
                              k = k,
                              starting_seed = 599) {
  result <- resample_function(data = data, k = k, starting_seed = starting_seed)
  
  # Absolute value the entire matrix, for all matrices
  absolute_sum <- lapply(result, abs)
  
  # Get the sum of absolute values in the final matrix
  absolute_final <- absolute_sum |> 
    reduce(`+`)
  
  # Get the sum of values in the final matrix
  numerator <- result |> 
    reduce(`+`)
  
  # Returns the matrix of zero-removed means. 
  # The zero-removed mean is the sum over the (length - the number of zeroes).
  # The length - the number of zeroes is equivalent to the sum over absolute values
  return(numerator / absolute_final)
}
```

## For one mean matrix, return a squared metric distance from 1.

```{r}
squared_distance_from_one <- function(mean_matrix = mean_matrix) {
  res_vec <- as.vector(mean_matrix)
  res_vec <- abs(res_vec[!is.na(res_vec)])
  return(sum((1 - res_vec)^2))
}
```

```{r}
data <- penguins
data <- data |> 
  drop_na() |> 
  mutate(bill_length_mm = scale(bill_length_mm),
         flipper_length_mm = scale(flipper_length_mm))

# m <- one_k_mean_matrix(data = data, k = 3)
```

```{r}
list_res <- lapply(c(2:5), function(x) one_k_mean_matrix(data = data,
                                                          k = x))
```

```{r}
lapply(list_res, function(x) squared_distance_from_one(x))
```

```{r}
image_helper <- function(list_res = list_res) {
  lapply(list_res, function(x) image(x))
}
```

```{r}
image_helper(list_res)
```

# Test with random data

```{r}
set.seed(599)
random_data <- data.frame(cbind(runif(100), runif(100)))
random_data <- random_data |> 
  mutate(X1 = scale(X1),
         X2 = scale(X2))

random_data |> 
  ggplot(aes(x = X1, y = X2)) +
  geom_point() +
  theme_minimal()


```

```{r}
list_res_unif <- lapply(c(2:5), function(x) one_k_mean_matrix(data = random_data,
                                                          k = x))
lapply(list_res_unif, function(x) squared_distance_from_one(x))
```

```{r}
kmeans <- k_means(num_clusters = 3) |>
      fit(~ X1 + X2,
          data = random_data)

kmeans$fit$cluster

random_data |> 
  ggplot(aes(x = X1, y = X2, color = as.factor(kmeans$fit$cluster))) +
  geom_point() +
  theme_minimal()
```

```{r}
image_helper(list_res_unif)
```

# Test with random normal variables

```{r}
random_normal <- rbind(data.frame(cbind(rnorm(50), rnorm(50))),
                       data.frame(cbind(rnorm(50, mean = 0 + 5), rnorm(50, mean = 0 + 5))))

random_normal <- random_normal |> 
  mutate(X1 = scale(X1),
         X2 = scale(X2))

random_normal |> 
  ggplot(aes(x = X1, y = X2)) +
  geom_point()


```

```{r}
list_res_norm <- lapply(c(2:5), function(x) one_k_mean_matrix(data = random_normal,
                                                          k = x))
lapply(list_res_norm, function(x) squared_distance_from_one(x))
```

```{r}
image_helper(list_res_norm)
```

```{r}
random_normal_2 <- rbind(data.frame(cbind(rnorm(50), rnorm(50))),
                       data.frame(cbind(rnorm(50, mean = 0 + 3), rnorm(50, mean = 0 + 3))),
                       data.frame(cbind(rnorm(50, mean = 3), rnorm(50, mean = 0 - 4))))

random_normal_2 <- random_normal_2 |> 
  mutate(X1 = scale(X1),
         X2 = scale(X2))

random_normal_2 |> 
  ggplot(aes(x = X1, y = X2)) +
  geom_point()

```

```{r}
list_res_normal_2 <- lapply(c(2:5), function(x) one_k_mean_matrix(data = random_normal_2,
                                                          k = x))
lapply(list_res_normal_2, function(x) squared_distance_from_one(x))
```

```{r}
image_helper(list_res_normal_2)
```


```{r}

```

