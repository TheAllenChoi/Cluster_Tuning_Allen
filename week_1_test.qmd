---
title: "Buddy System Testing"
format: html
editor: visual
---

## Idea

What principle are you using to measure a "good" cluster?\
Why does this make sense? How would this be tuned - that is, what resampling does it need? Does this apply in general, or only for a particular type of clustering algorithm? Link any references that might help support this.

## Metric Calculation

Write a function here that calculates your "tuning metric" for a particular value of k.

```{r}
# Closely follows the algorithm set in Ben-Hur and Elisseeff paper: A stability based method for discovering structure in clustered data (2002)
library(tidyclust)
library(tidyverse)
library(tidymodels)
# For a given k, we want to resample j times. 
# We need an index of every single observation in order to be able to compare consistently
# across all resamples.

k <- 3
# set up k = 3 for initial testing
data(penguins)
data <- penguins

# For a given k:
  # Add an index column to keep track of observations even after shuffling
  # Iterate over the resample amounts (from 1:j)
    # first_data <- Randomly select 80% of the data
    # clust_assignment <- clust(first_data)
    
    # Convert clust_assignment to matrix form (this is the difficult part)
      # The matrix is NA if the observation is being compared with itself (i = j)
      # The matrix is symmetrical
      # The value is equal to 1 if the observation is within the same cluster
      # The value is equal to -1 if the observation is not in the same cluster
      # The value is equal to 0 if either observation does not exist in that resample.
  
# Variable init
k <- 3
number_of_resamples <- 1
proportion_resample <- 0.8
data$index <- 1:nrow(data)
results <- list()
result_matrix <- matrix(0, nrow = nrow(data), ncol = nrow(data))

# Remove NA values before passing in since we can't handle NA values rn lmao
data <- data |> 
  drop_na()

# For loop
for (i in 1:number_of_resamples) {
  # 80% resample
  random_sample <- data |> 
    filter(index %in% sample(index, proportion_resample * nrow(data)))
  
  # Run k-means on resample
  kmeans <- k_means(num_clusters = k) |> 
    fit(~ bill_length_mm + flipper_length_mm,
        data = random_sample)
  
  intermediate <- data.frame(random_sample$index,
                             extract_cluster_assignment(kmeans) |> mutate(.cluster = as.character(.cluster)),
                             stringsAsFactors = FALSE)
  colnames(intermediate) <- c("index", "cluster")
  
  # I don't know how to vectorize this :(
  for (n in 1:nrow(intermediate)) {
    for (m in 1:nrow(intermediate)) {
      # if the points are the same then set to NA
      if (intermediate[n, ]$index == intermediate[m, ]$index) {
        
        # problem here
        result_matrix[intermediate[n, ]$index, intermediate[m, ]$index] <- NA
      } else {
        # get first pointer cluster
        first <- intermediate[n, ]$cluster
        # get second pointer cluster
        second <- intermediate[m, ]$cluster
        
        # if clusters are the same
        if (first == second) {
          result_matrix[intermediate[n, ]$index, intermediate[m, ]$index] <- 1
        } else {
          # if clusters are different
          result_matrix[intermediate[n, ]$index, intermediate[m, ]$index] <- -1
        }
      }

      
    }
  }
}

```

## Experiments

On either simluated data or real data with known structure, run several replications of your experiment for each of various k's. Make sure to set a seed.

## Results

What did your experiments show? Why do you think this happened? Is there anything promising here?
